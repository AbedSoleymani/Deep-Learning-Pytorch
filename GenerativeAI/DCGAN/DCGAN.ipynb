{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is notebook implementation of the DCGAN for utilizing free GPUs of GoogleColab!"
      ],
      "metadata": {
        "id": "JmQzCeFCOGI9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p7OLrXgtNXBW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, channels_img, features_d):\n",
        "        super(Discriminator, self).__init__()\n",
        "        \"\"\"In the paper they did not use BN in the first layer of Discriminator\n",
        "           and in the last layer of Generator. This is why we do not use _block\n",
        "           rightaway!\n",
        "        \"\"\"\n",
        "        self.disc = nn.Sequential(\n",
        "            # Input: N x channels_img x 64 x64\n",
        "            nn.Conv2d(in_channels=channels_img,\n",
        "                      out_channels=features_d,\n",
        "                      kernel_size=4,\n",
        "                      stride=2,\n",
        "                      padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            # Input: N x features_d x 32 x 32\n",
        "            self._block(in_channels=features_d,\n",
        "                        out_channels=features_d*2,\n",
        "                        kernel_size=4,\n",
        "                        stride=2,\n",
        "                        padding=1),\n",
        "\n",
        "            # Input: N x features_d*2 x 16 x 16\n",
        "            self._block(in_channels=features_d*2,\n",
        "                        out_channels=features_d*4,\n",
        "                        kernel_size=4,\n",
        "                        stride=2,\n",
        "                        padding=1),\n",
        "\n",
        "            # Input: N x features_d*4 x 8 x 8\n",
        "            self._block(in_channels=features_d*4,\n",
        "                        out_channels=features_d*8,\n",
        "                        kernel_size=4,\n",
        "                        stride=2,\n",
        "                        padding=1),\n",
        "\n",
        "            # Input: N x features_d*8 x 4 x 4\n",
        "            nn.Conv2d(in_channels=features_d*8,\n",
        "                      out_channels=1,\n",
        "                      kernel_size=4,\n",
        "                      stride=2,\n",
        "                      padding=0),\n",
        "            # Output: N x 1 x 1 x 1\n",
        "\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=out_channels,\n",
        "                kernel_size=kernel_size,\n",
        "                stride=stride,\n",
        "                padding=padding,\n",
        "                bias=False, # Since we are using BN\n",
        "            ),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.disc(x)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim, channels_img, features_g):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.gen = nn.Sequential(\n",
        "            # Input: N × z_dim x 1 x 1\n",
        "            self._block(in_channels=z_dim,\n",
        "                        out_channels=features_g*16,\n",
        "                        kernel_size=4,\n",
        "                        stride=1,\n",
        "                        padding=0),\n",
        "\n",
        "            # Input: N x features_g*16 × 4 x 4\n",
        "            self._block(in_channels=features_g*16,\n",
        "                        out_channels=features_g*8,\n",
        "                        kernel_size=4,\n",
        "                        stride=2,\n",
        "                        padding=1),\n",
        "\n",
        "            # Input: N x features_g*8 × 8 x 8\n",
        "            self._block(in_channels=features_g*8,\n",
        "                        out_channels=features_g*4,\n",
        "                        kernel_size=4,\n",
        "                        stride=2,\n",
        "                        padding=1),\n",
        "\n",
        "            # Input: N x features_g*4 × 16 x 16\n",
        "            self._block(in_channels=features_g*4,\n",
        "                        out_channels=features_g*2,\n",
        "                        kernel_size=4,\n",
        "                        stride=2,\n",
        "                        padding=1),\n",
        "\n",
        "            # Input: N x features_g*2 × 32 x 32\n",
        "            nn.ConvTranspose2d(\n",
        "                in_channels=features_g*2,\n",
        "                out_channels=channels_img,\n",
        "                kernel_size=4,\n",
        "                stride=2,\n",
        "                padding=1,\n",
        "            ),\n",
        "\n",
        "            # Output: N x channels_img × 64 x 64\n",
        "            nn.Tanh(), # to map the output to [-1, 1]\n",
        "        )\n",
        "\n",
        "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        return nn.Sequential(\n",
        "            nn.ConvTranspose2d(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=out_channels,\n",
        "                kernel_size=kernel_size,\n",
        "                stride=stride,\n",
        "                padding=padding,\n",
        "                bias=False, # Since we are using BN\n",
        "            ),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.gen(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"initialize_weights function is based on instructions in the original paper\"\"\"\n",
        "def initialize_weights(model):\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
        "            nn.init.normal_(module.weight.data, 0.0, 0.02)"
      ],
      "metadata": {
        "id": "H353jvbVNq12"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Testing the created architecture \"\"\"\n",
        "batch_size, channels_img, heigh, width, z_dim = 8, 3, 64, 64, 100\n",
        "\n",
        "rand_img_batch = torch.randn((batch_size, channels_img, heigh, width))\n",
        "rand_z = torch.randn((batch_size, z_dim, 1, 1))\n",
        "\n",
        "gen = Generator(z_dim=z_dim, channels_img=channels_img, features_g=8)\n",
        "initialize_weights(gen)\n",
        "disc =Discriminator(channels_img=channels_img, features_d=8)\n",
        "initialize_weights(disc)\n",
        "\n",
        "assert gen(rand_z).shape == (batch_size, channels_img, heigh, width)\n",
        "assert disc(rand_img_batch).shape == (batch_size, 1, 1, 1)\n",
        "\n",
        "print(\"success!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78Bac1SbNuqm",
        "outputId": "8acc3e03-e3c1-4a0d-db6b-65e4c1b28555"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "success!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_png(im, file_path):\n",
        "    rows, cols = 4, 8\n",
        "\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(16, 8))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i in range(len(axes)):\n",
        "        axes[i].imshow(im[i], cmap='gray')\n",
        "        axes[i].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(file_path)\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "Bnj1kT61hEXA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from matplotlib import image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOzqI5cQODm6",
        "outputId": "c7a69d42-6eb8-4ee0-de3d-12491fed6185"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Hyperparameters \"\"\"\n",
        "batch_size = 128\n",
        "img_size = 64\n",
        "channels_img = 1 # for mnist\n",
        "z_dim = 100\n",
        "features_disc = 64\n",
        "features_gen = 64\n",
        "\n",
        "transforms = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5] * channels_img, [0.5] * channels_img)\n",
        "])"
      ],
      "metadata": {
        "id": "6PGt02aBOdPh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.MNIST(root= \"./GenerativeAI/DCGAN/dataset/\", train=True, transform=transforms, download=True)\n",
        "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "gen = Generator(z_dim, channels_img, features_gen).to(device)\n",
        "disc = Discriminator(channels_img, features_disc).to(device)\n",
        "initialize_weights(gen)\n",
        "initialize_weights(disc)\n",
        "\n",
        "lr = 1e-3\n",
        "opt_gen = optim.Adam(gen.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "opt_disc = optim.Adam(disc.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "fixed_noise = torch.randn(32, z_dim, 1, 1).to(device)\n",
        "\n",
        "import os\n",
        "save_path = \"./GenerativeAI/DCGAN/logs/fake\"\n",
        "os.makedirs(save_path, exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pULSATTzOvOS",
        "outputId": "2748efb3-d265-41eb-b2da-bcd27fb06303"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./GenerativeAI/DCGAN/dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 116644814.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./GenerativeAI/DCGAN/dataset/MNIST/raw/train-images-idx3-ubyte.gz to ./GenerativeAI/DCGAN/dataset/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./GenerativeAI/DCGAN/dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 121135693.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./GenerativeAI/DCGAN/dataset/MNIST/raw/train-labels-idx1-ubyte.gz to ./GenerativeAI/DCGAN/dataset/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./GenerativeAI/DCGAN/dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 49535446.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./GenerativeAI/DCGAN/dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to ./GenerativeAI/DCGAN/dataset/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./GenerativeAI/DCGAN/dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 23842964.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./GenerativeAI/DCGAN/dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./GenerativeAI/DCGAN/dataset/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "step = 0\n",
        "gen.train()\n",
        "disc.train()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for batch_idx, (real, _) in enumerate(loader):\n",
        "        gen.train()\n",
        "        disc.train()\n",
        "        real = real.to(device)\n",
        "        noise = torch.randn((batch_size, z_dim, 1, 1)).to(device)\n",
        "        fake = gen(noise)\n",
        "\n",
        "        # Train Discriminator: max{Log[D(x)] + Log[1 - D(G(Z))]}\n",
        "        disc_real = disc(real).view(-1)\n",
        "        loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n",
        "        disc_fake = disc(fake.detach()).view(-1)\n",
        "        loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
        "        loss_disc = (loss_disc_real + loss_disc_fake) / 2\n",
        "\n",
        "        disc.zero_grad()\n",
        "        \"\"\" `retain_graph=True` in the next line of code:\n",
        "            Retains the computational graph for subsequent backward passes\n",
        "        \"\"\"\n",
        "        loss_disc.backward(retain_graph=True)\n",
        "        opt_disc.step()\n",
        "\n",
        "        # Train Generator: min{Log[1 - D(G(Z))]} or equivalently max{Log[D(G(Z))]}\n",
        "        disc_fake = disc(fake).view(-1)\n",
        "        loss_gen = criterion(disc_fake, torch.ones_like(disc_fake))\n",
        "\n",
        "        gen.zero_grad()\n",
        "        loss_gen.backward()\n",
        "        opt_gen.step()\n",
        "\n",
        "        if batch_idx % 50 == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch+1}/{epochs}] Batch {batch_idx}/{len(loader)} \"\n",
        "                f\"Loss D: {loss_disc:.4f}, Loss G: {loss_gen:.4f}\"\n",
        "            )\n",
        "\n",
        "            gen.eval()\n",
        "            with torch.no_grad():\n",
        "                fake = gen(fixed_noise)\n",
        "                img_grid_fake = torchvision.utils.make_grid(fake[:32,0,:,:], normalize=True)\n",
        "                file_path = f\"{save_path}/{str(step)}.png\"\n",
        "                im = img_grid_fake.cpu().numpy()\n",
        "                save_png(im, file_path)\n",
        "\n",
        "            step += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkXRPB3FOzDl",
        "outputId": "577d503e-3c02-409e-a8a8-e0e356b84c48"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5] Batch 0/469 Loss D: 0.6967, Loss G: 0.8920\n",
            "Epoch [1/5] Batch 50/469 Loss D: 0.0094, Loss G: 5.1445\n",
            "Epoch [1/5] Batch 100/469 Loss D: 1.4640, Loss G: 0.2331\n",
            "Epoch [1/5] Batch 150/469 Loss D: 0.6866, Loss G: 1.4222\n",
            "Epoch [1/5] Batch 200/469 Loss D: 0.8595, Loss G: 1.9036\n",
            "Epoch [1/5] Batch 250/469 Loss D: 0.5050, Loss G: 1.4846\n",
            "Epoch [1/5] Batch 300/469 Loss D: 0.5714, Loss G: 0.8957\n",
            "Epoch [1/5] Batch 350/469 Loss D: 0.6296, Loss G: 1.1622\n",
            "Epoch [1/5] Batch 400/469 Loss D: 0.6477, Loss G: 1.0051\n",
            "Epoch [1/5] Batch 450/469 Loss D: 0.6515, Loss G: 0.9191\n",
            "Epoch [2/5] Batch 0/469 Loss D: 0.6293, Loss G: 0.9646\n",
            "Epoch [2/5] Batch 50/469 Loss D: 0.6937, Loss G: 0.7641\n",
            "Epoch [2/5] Batch 100/469 Loss D: 0.6266, Loss G: 0.8574\n",
            "Epoch [2/5] Batch 150/469 Loss D: 0.7695, Loss G: 1.1388\n",
            "Epoch [2/5] Batch 200/469 Loss D: 0.5710, Loss G: 1.4093\n",
            "Epoch [2/5] Batch 250/469 Loss D: 0.5734, Loss G: 1.1349\n",
            "Epoch [2/5] Batch 300/469 Loss D: 0.6286, Loss G: 1.1144\n",
            "Epoch [2/5] Batch 350/469 Loss D: 0.5550, Loss G: 1.3815\n",
            "Epoch [2/5] Batch 400/469 Loss D: 0.7658, Loss G: 2.5371\n",
            "Epoch [2/5] Batch 450/469 Loss D: 0.5659, Loss G: 1.2645\n",
            "Epoch [3/5] Batch 0/469 Loss D: 0.5111, Loss G: 2.2151\n",
            "Epoch [3/5] Batch 50/469 Loss D: 0.3180, Loss G: 2.2873\n",
            "Epoch [3/5] Batch 100/469 Loss D: 0.3703, Loss G: 2.3233\n",
            "Epoch [3/5] Batch 150/469 Loss D: 0.3003, Loss G: 2.4006\n",
            "Epoch [3/5] Batch 200/469 Loss D: 0.1185, Loss G: 2.9260\n",
            "Epoch [3/5] Batch 250/469 Loss D: 0.4657, Loss G: 2.9690\n",
            "Epoch [3/5] Batch 300/469 Loss D: 0.4835, Loss G: 4.3886\n",
            "Epoch [3/5] Batch 350/469 Loss D: 0.1583, Loss G: 3.2609\n",
            "Epoch [3/5] Batch 400/469 Loss D: 0.0266, Loss G: 4.4178\n",
            "Epoch [3/5] Batch 450/469 Loss D: 0.2384, Loss G: 4.5999\n",
            "Epoch [4/5] Batch 0/469 Loss D: 0.5138, Loss G: 1.7205\n",
            "Epoch [4/5] Batch 50/469 Loss D: 0.0742, Loss G: 3.0000\n",
            "Epoch [4/5] Batch 100/469 Loss D: 0.4544, Loss G: 1.4253\n",
            "Epoch [4/5] Batch 150/469 Loss D: 0.9225, Loss G: 1.2878\n",
            "Epoch [4/5] Batch 200/469 Loss D: 0.3552, Loss G: 2.2511\n",
            "Epoch [4/5] Batch 250/469 Loss D: 0.0148, Loss G: 4.6399\n",
            "Epoch [4/5] Batch 300/469 Loss D: 0.0107, Loss G: 4.6409\n",
            "Epoch [4/5] Batch 350/469 Loss D: 0.7997, Loss G: 0.6397\n",
            "Epoch [4/5] Batch 400/469 Loss D: 0.5395, Loss G: 1.0947\n",
            "Epoch [4/5] Batch 450/469 Loss D: 0.4286, Loss G: 3.8555\n",
            "Epoch [5/5] Batch 0/469 Loss D: 0.3963, Loss G: 2.4510\n",
            "Epoch [5/5] Batch 50/469 Loss D: 0.1331, Loss G: 3.3248\n",
            "Epoch [5/5] Batch 100/469 Loss D: 0.4697, Loss G: 1.6603\n",
            "Epoch [5/5] Batch 150/469 Loss D: 0.2946, Loss G: 2.5081\n",
            "Epoch [5/5] Batch 200/469 Loss D: 0.0299, Loss G: 4.2593\n",
            "Epoch [5/5] Batch 250/469 Loss D: 0.0089, Loss G: 5.2848\n",
            "Epoch [5/5] Batch 300/469 Loss D: 0.0118, Loss G: 4.9597\n",
            "Epoch [5/5] Batch 350/469 Loss D: 0.4071, Loss G: 2.1984\n",
            "Epoch [5/5] Batch 400/469 Loss D: 0.3877, Loss G: 2.0218\n",
            "Epoch [5/5] Batch 450/469 Loss D: 0.7611, Loss G: 1.6260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "image_directory = \"./GenerativeAI/DCGAN/logs/fake/\"\n",
        "\n",
        "output_gif_path = \"./GenerativeAI/DCGAN/generated_gif.gif\"\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "for i in range(step):\n",
        "    image_paths.append(os.path.join(image_directory, f\"{i}\"))\n",
        "\n",
        "with imageio.get_writer(output_gif_path, duration=0.5) as gif_writer:\n",
        "    for i, image_path in enumerate(image_paths):\n",
        "        image = imageio.imread(f\"{image_path}.png\")\n",
        "\n",
        "        step_number_text = f\"Step: {i+1}\"\n",
        "        image = Image.fromarray(image)\n",
        "        draw = ImageDraw.Draw(image)\n",
        "\n",
        "        font = ImageFont.load_default()\n",
        "\n",
        "        draw.text((10, 10), step_number_text, font=font, fill=(255, 0, 0))\n",
        "\n",
        "\n",
        "        gif_writer.append_data(image)\n",
        "\n",
        "print(f\"GIF created and saved at: {output_gif_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjiCkoSXQwL2",
        "outputId": "d26ac2b4-1383-4e50-ebf9-b1d47aa30e9d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-9ef546f800cf>:15: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  image = imageio.imread(f\"{image_path}.png\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GIF created and saved at: ./GenerativeAI/DCGAN/generated_gif.gif\n"
          ]
        }
      ]
    }
  ]
}